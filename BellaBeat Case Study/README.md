<p align="center">
  <img width="200" height="200" src="https://github.com/powellot/GoogleCareerCertificate/blob/main/Resources/bellabeat.png">
</p>

# Bellabeat Case Study 
### How can a wellness company play it smart?

### Table of Contents                     
  - [Scenario](#scenario)
  - [Stage 1: Ask](#stage-1-ask)
  - [Stage 2: Prepare](#stage-2-prepare)
  - [Stage 3: Process](#stage-3-process)
  - [Stage 4: Analyze](#stage-4-analyze)
  - [Stage 5: Share]()
  - [Stage 6: Act]()
  

### Scenario
> You are a junior data analyst working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women. Bellabeat is a successful small company, but they have the potential to become a larger player in the global smart device market. Urška Sršen, co-founder and Chief Creative Officer of Bellabeat believes that analyzing smart device fitness data could help unlock new growth opportunities for the company. You have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights you discover will then help guide the marketing strategy for the company. You will present your analysis to the Bellabeat executive team along with your high-level recommendations for Bellabeat’s marketing strategy.

We have been tasked with answering three questions:

```
  1. What are some trends in smart-device usage?
  2. How could these trends apply to Bellabeat customers?
  3. How could these trends help influence Bellabeat's marketing strategy?
```

To effectively and concisely answer these questions with relevant and accurate data, I will be using the 6 step data analysis process: ask, prepare, analyze, share, and act.

## Stage 1: Ask
### Background

> Bellabeat is a wellness company founded by Urška Sršen and Sandro Mur in 2014. It is best known for its Leaf smart jewelry wearable line. The company has offices in San Francisco, Zagreb and Hong Kong. [Wikipedia](https://en.wikipedia.org/wiki/Bellabeat)

The overall goal of this project is to analyze smart device usage to gain insight into how non-Bellabeat smart devices are being used to guide the Bellabeat marketing strategy.

In addition to answering the three questions listed in the [scenario](#scenario) section of this write-up, I need to be able to deliver the following:

```
  1. A summary of the business task.
  2. A description of the data sources used.
  3. Documentation of any cleaning or manipulation of data.
  4. A summary of the analysis.
  5. High-level content recommendations based on the analysis.
```

With this in mind. I'm ready to move on to the 'prepare' phase of my analysis.

## Stage 2: Prepare
The data used in this case study is Fitbit Fitness Tracker from Kaggle generated by a survey from Amazon Mechanical Turk between March 12th, 2016, and May 12th, 2016. It contains the personal fitness tracker information from 30 Fitbit users who consented to the use of their personal activity information including daily activity, steps, and heart rate. This data is stored in 18 .csv files.

### Data Integrity & Limitations
At the time of writing, it is June 2023. This data was collected in 2016 meaning it may not be relevant to the company anymore due to a change in a user's activity, sleep, and lifestyle in the last seven years. Additionally, the small sample size of 30 is inadequate to represent the entirety of the female Fitbit user population. Finally, the data contains no information on the age of each individual, a crucial metric when analyzing health and fitness.

A good data source is reliable, original, comprehensive, current, and cited (ROCCC). Using this to check the Fitbit user data:

- [ ] Reliable
  - Unreliable due to the small sample size.
- [ ] Original
  - Unoriginal data as it was collected by a third party.
- [X] Comprehensive
  - Collected data matches Bellabeat products.
- [ ] Current
  - Not current as data was collected over seven years ago.
- [ ] Cited
  - Not cited, third-party data.

Using this check, we can see the Fitbit data only meets one of our five criteria to be a good data source. I will continue with my analysis, however, there will be an asterisk so to speak on any conclusions drawn from this dataset as it is unfit for use in a professional setting.

## Stage 3: Process

As there is a relatively large number of .csv files and R or Python are better suited than spreadsheets for this analysis, R programming has been used for this particular case study in RStudio Cloud.

This section is particularly long as it goes into every step of my preparation for analysis. For reader convenience, a table of contents for this section has been provided below:
#### Section Links
  - [Installing & Loading Common Packages & Libraries](#installing--loading-common-packages--libraries)
  - [Importing Data Into R](#importing-data-into-r)
  - [Exploring Key Tables](#exploring-key-tables)
  - [Data Cleaning](#data-cleaning)
    - [Checking Data Values](#checking-data-values)
    - [Checking for Missing Values](#checking-for-missing-values)
    - [Checking Number of Unique Participiants](#checking-number-of-unique-participants)
  - [Data Summary](#data-summary)

### Installing & Loading Common Packages & Libraries
'##' *Indicates a console output.*

```r
install.packages('tidyverse')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(tidyverse)

## ── Attaching core tidyverse packages ───────────────────────────── tidyverse 2.0.0 ──
## ✔ dplyr     1.1.2     ✔ readr     2.1.4
## ✔ forcats   1.0.0     ✔ stringr   1.5.0
## ✔ ggplot2   3.4.2     ✔ tibble    3.2.1
## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
## ✔ purrr     1.0.1 
## ── Conflicts ─────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
```
```r
install.packages('here')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(here)

## here() starts at /cloud/project
```
```r
install.packages('skimr')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(skimr)

## Attaching package: 'skimr'
```
```r
install.packages('janitor')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(janitor)

## Attaching package: ‘janitor’
##
## The following objects are masked from 'package:stats':
## 
##     chisq.test, fisher.test
```
```r
install.packages('dplyr')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(dplyr)

## Attaching package: ‘dplyr’
```
```r
install.packages('ggplot2')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(ggplot2)
```
```r
install.packages('lubridate')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(lubridate)

## Attaching package: ‘lubridate’
##
## The following objects are masked from ‘package:base’:
##
##     date, intersect, setdiff, union
```
```r
install.packages('RColorBrewer')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
##(as ‘lib’ is unspecified)
```
```r
library(RColorBrewer)
```

In order to make the findings of the analysis more accessible, I then selected a colorblind-friendly color pallet using RColorBrewer. I wanted a vibrant, high-contrast, limited color pallet in order to make sure that all viewers of the graphs and charts are easily able to distinguish between categories.

```r
display.brewer.all(colorblindFriendly = T)
```
![RColorBrewer Colorblind Pallets](https://github.com/powellot/GoogleCareerCertificate/blob/main/Resources/brewerColorBlind.png)

*All brewer color pallets that are colorblind-friendly.*

```r
display.brewer.pal(5, "Set2")
```
![RColorBrewer pallet I use](https://github.com/powellot/GoogleCareerCertificate/blob/main/Resources/brewerColorBlindPallet.png)

*The brewer color pallet I will be using for this analysis.*

### Importing Data Into R
To begin, I created two data frames 'day_activity' and 'sleep_day' from the CSV files from the datasets.
```r
daily_activity <- read.csv("dailyActivity_merged.csv")
sleep_day <- read.csv("sleepDay_merged.csv")
```
### Exploring Key Tables
This was to check the basic information of each dataset. Namely the column names, number of observations, data type, formatting, and be sure there were no missing values.

Taking a look at the 'daily_activity' data:
```r
head(daily_activity)

##           Id ActivityDate TotalSteps TotalDistance TrackerDistance LoggedActivitiesDistance VeryActiveDistance
## 1 1503960366    4/12/2016      13162          8.50            8.50                        0               1.88
## 2 1503960366    4/13/2016      10735          6.97            6.97                        0               1.57
## 3 1503960366    4/14/2016      10460          6.74            6.74                        0               2.44
## 4 1503960366    4/15/2016       9762          6.28            6.28                        0               2.14
## 5 1503960366    4/16/2016      12669          8.16            8.16                        0               2.71
## 6 1503960366    4/17/2016       9705          6.48            6.48                        0               3.19
##   ModeratelyActiveDistance LightActiveDistance SedentaryActiveDistance VeryActiveMinutes FairlyActiveMinutes
## 1                     0.55                6.06                       0                25                  13
## 2                     0.69                4.71                       0                21                  19
## 3                     0.40                3.91                       0                30                  11
## 4                     1.26                2.83                       0                29                  34
## 5                     0.41                5.04                       0                36                  10
## 6                     0.78                2.51                       0                38                  20
##   LightlyActiveMinutes SedentaryMinutes Calories
## 1                  328              728     1985
## 2                  217              776     1797
## 3                  181             1218     1776
## 4                  209              726     1745
## 5                  221              773     1863
## 6                  164              539     1728
```

Identifying all of the column names in the 'daily_activity' data:
```r
colnames(daily_activity)

##  [1] "Id"                       "ActivityDate"             "TotalSteps"               "TotalDistance"           
##  [5] "TrackerDistance"          "LoggedActivitiesDistance" "VeryActiveDistance"       "ModeratelyActiveDistance"
##  [9] "LightActiveDistance"      "SedentaryActiveDistance"  "VeryActiveMinutes"        "FairlyActiveMinutes"     
## [13] "LightlyActiveMinutes"     "SedentaryMinutes"         "Calories"
```

Taking a look at the 'sleep_day' data:
```r
head(sleep_day)

##           Id              SleepDay TotalSleepRecords TotalMinutesAsleep TotalTimeInBed
## 1 1503960366 4/12/2016 12:00:00 AM                 1                327            346
## 2 1503960366 4/13/2016 12:00:00 AM                 2                384            407
## 3 1503960366 4/15/2016 12:00:00 AM                 1                412            442
## 4 1503960366 4/16/2016 12:00:00 AM                 2                340            367
## 5 1503960366 4/17/2016 12:00:00 AM                 1                700            712
## 6 1503960366 4/19/2016 12:00:00 AM                 1                304            320
```

Identifying all of the column names in the 'sleep_day' data:
```r
colnames(sleep_day)

## [1] "Id"                 "SleepDay"           "TotalSleepRecords"  "TotalMinutesAsleep" "TotalTimeInBed"  
```

Using this information, I could see that the "Id" field is shared between the two datasets meaning I can use that information to merge the two datasets.

### Data Cleaning
To ensure accuracy when merging the two datasets, I clean the data by checking for missing values, content, duplicates, and misspellings.

#### Checking Data Values
```r
str(daily_activity)

## 'data.frame':	940 obs. of  15 variables:
##  $ Id                      : num  1.5e+09 1.5e+09 1.5e+09 1.5e+09 1.5e+09 ...
##  $ ActivityDate            : chr  "4/12/2016" "4/13/2016" "4/14/2016" "4/15/2016" ...
##  $ TotalSteps              : int  13162 10735 10460 9762 12669 9705 13019 15506 10544 9819 ...
##  $ TotalDistance           : num  8.5 6.97 6.74 6.28 8.16 ...
##  $ TrackerDistance         : num  8.5 6.97 6.74 6.28 8.16 ...
##  $ LoggedActivitiesDistance: num  0 0 0 0 0 0 0 0 0 0 ...
##  $ VeryActiveDistance      : num  1.88 1.57 2.44 2.14 2.71 ...
##  $ ModeratelyActiveDistance: num  0.55 0.69 0.4 1.26 0.41 ...
##  $ LightActiveDistance     : num  6.06 4.71 3.91 2.83 5.04 ...
##  $ SedentaryActiveDistance : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ VeryActiveMinutes       : int  25 21 30 29 36 38 42 50 28 19 ...
##  $ FairlyActiveMinutes     : int  13 19 11 34 10 20 16 31 12 8 ...
##  $ LightlyActiveMinutes    : int  328 217 181 209 221 164 233 264 205 211 ...
##  $ SedentaryMinutes        : int  728 776 1218 726 773 539 1149 775 818 838 ...
##  $ Calories                : int  1985 1797 1776 1745 1863 1728 1921 2035 1786 1775 ...
```
```r
str(sleep_day)

## 'data.frame':	413 obs. of  5 variables:
 $ Id                : num  1.5e+09 1.5e+09 1.5e+09 1.5e+09 1.5e+09 ...
 $ SleepDay          : chr  "4/12/2016 12:00:00 AM" "4/13/2016 12:00:00 AM" "4/15/2016 12:00:00 AM" "4/16/2016 12:00:00 AM" ...
 $ TotalSleepRecords : int  1 2 1 2 1 1 1 1 1 1 ...
 $ TotalMinutesAsleep: int  327 384 412 340 700 304 360 325 361 430 ...
 $ TotalTimeInBed    : int  346 407 442 367 712 320 377 364 384 449 ...
```
#### Checking for Missing Values
```r
which(is.na(daily_activity))

## integer(0)
```
```r
which(is.na(sleep_day))

## integer(0)
```
#### Checking Number of Unique Participants
```r
n_distinct(daily_activity$Id)

## [1] 33
```
```r
n_distinct(sleep_day$Id)

## [1] 24
```
### Data Summary
I learned from these data points that there are 33 unique user IDs, not the 30 the dataset claimed. Additionally, there are more users in the daily activity data set than in the sleep dataset, 33 and 24, respectively. Finally, the Activity Date is of type char, not Date, and the data set has no missing values.

Now that the data has been cleaned, I can begin my analysis.

## Stage 4: Analyze
### Summarize the Statistics
First, we are going to check observations in each data frame:
```r
nrow(daily_activity)

## [1] 940
```
```r
nrow(sleep_day)

## [1] 413
```

Find our key statistics from each data frame with pipelining for 'daily_activity':
```r
daily_activity %>%
  select(TotalSteps, SedentaryMinutes, Calories) %>%
  summary()

##    TotalSteps    SedentaryMinutes    Calories   
##  Min.   :    0   Min.   :   0.0   Min.   :   0  
##  1st Qu.: 3790   1st Qu.: 729.8   1st Qu.:1828  
##  Median : 7406   Median :1057.5   Median :2134  
##  Mean   : 7638   Mean   : 991.2   Mean   :2304  
##  3rd Qu.:10727   3rd Qu.:1229.5   3rd Qu.:2793  
##  Max.   :36019   Max.   :1440.0   Max.   :4900  
```
Per these statistics, the average user:
1. Was only taking 7,406 steps per day.
   - The CDC recommends a daily minimum of 10,000 steps.
2. Was spending 1,507.5 minutes of 1440 minutes per day inactive.
3. Was burning 2,134 calories per day.

Key statistics for the 'sleep_day' data frame using pipelining:
```r
sleep_day %>%
  select(TotalSleepRecords, TotalMinutesAsleep, TotalTimeInBed) %>%
  summary()

##  TotalSleepRecords TotalMinutesAsleep TotalTimeInBed 
##  Min.   :1.000     Min.   : 58.0      Min.   : 61.0  
##  1st Qu.:1.000     1st Qu.:361.0      1st Qu.:403.0  
##  Median :1.000     Median :433.0      Median :463.0  
##  Mean   :1.119     Mean   :419.5      Mean   :458.6  
##  3rd Qu.:1.000     3rd Qu.:490.0      3rd Qu.:526.0  
##  Max.   :3.000     Max.   :796.0      Max.   :961.0  
```
Per these statistics, the average user:
1. Records sleep once per day.
2. Spends 458.6 minutes (~8 hours) in bed per night.
3. Sleeps for 419.5 minutes (~7 hours) per night.

### Identifying Trends and Relationships
#### The Relationship Between Steps and Sedentary Minutes
Key Questions:
  - What relationship exists between steps and sedentary minutes?
  - How can this relationship help inform or better appeal to our target customer base?
      - How can Bellabeat use this information to get their customers to walk more?

To analyze this, a plot was created:
```r
ggplot(data = daily_activity, aes(x = TotalSteps, y = SedentaryMinutes)) +
  geom_point(color = "darkgoldenrod2") +
  geom_smooth(color = "deepskyblue1")

## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'
```
![TotalSteps vs. SedentaryMinutes Graph](https://github.com/powellot/GoogleCareerCertificate/blob/main/Resources/SedentaryVsSteps.png)

This scatterplot shows a weak negative correlation between TotalSteps and SedentaryMinutes. Between 0 and 10,000 steps, we can see the Loess smoothing shows a strong decrease in SedentaryMinutes as TotalSteps increase. With this in mind, there is potential for a Bellabeat device to remind customers to move after a preset amount of time sedentary.

#### The Relationship Between Total Steps and Calories Burned
Key Questions:

#### The Relationship Between Total Time Asleep and Total Time in Bed
Key Questions:
- What relationship exists between time asleep and time in bed?
    - Is it linear as expected?
- Are there any unexpected trends?
- How can this help Bellabeat's marketing efforts?

```r
ggplot(data = sleep_day, aes(x = TotalMinutesAsleep, y = TotalTimeInBed)) +
  geom_point(color = "darkgoldenrod2") +
  geom_smooth(color = "deepskyblue1") 

## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'
```
![TimeAsleep vs. TimeInBed Graph](https://github.com/powellot/GoogleCareerCertificate/blob/main/Resources/TimeAsleepVsTimeInBed.png)

The above scatterplot shows a strong positive correlation between time spent in bed and total time asleep each night. This could be used to encourage users to get in bed earlier and therefore get more sleep each night.
