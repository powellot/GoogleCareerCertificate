<p align="center">
  <img width="200" height="200" src="https://github.com/powellot/GoogleCareerCertificate/blob/main/Resources/bellabeat.png">
</p>

# Bellabeat Case Study 
### How can a wellness company play it smart?

### Table of Contents                     
  - [Scenario](#scenario)
  - [Stage 1: Ask](#stage-1-ask)
  - [Stage 2: Prepare](#stage-2-prepare)
  - [Stage 3: Process](#stage-3-process)
  - [Stage 4: Analyze]()
  - [Stage 5: Share]()
  - [Stage 6: Act]()
  

### Scenario
> You are a junior data analyst working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women. Bellabeat is a successful small company, but they have the potential to become a larger player in the global smart device market. Urška Sršen, co-founder and Chief Creative Officer of Bellabeat believes that analyzing smart device fitness data could help unlock new growth opportunities for the company. You have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights you discover will then help guide the marketing strategy for the company. You will present your analysis to the Bellabeat executive team along with your high-level recommendations for Bellabeat’s marketing strategy.

We have been tasked with answering three questions:

```
  1. What are some trends in smart-device usage?
  2. How could these trends apply to Bellabeat customers?
  3. How could these trends help influence Bellabeat's marketing strategy?
```

In order to effectively and concisely answer these questions with relevant and accurate data, I will be using the 6 step data analysis process: ask, prepare, analyze, share, and act.

## Stage 1: Ask
### Background

> Bellabeat is a wellness company founded by Urška Sršen and Sandro Mur in 2014. It is best known for its Leaf smart jewelry wearable line. The company has offices in San Francisco, Zagreb and Hong Kong. [Wikipedia](https://en.wikipedia.org/wiki/Bellabeat)

The overall goal of this project is to analyze smart device usage to gain insight into how non-Bellabeat smart devices are being used to guide the Bellabeat marketing strategy.

In addition to answering the three questions listed in the [scenario](#scenario) section of this write-up, I need to be able to deliver the following:

```
  1. A summary of the business task.
  2. A description of the data sources used.
  3. Documentation of any cleaning or manipulation of data.
  4. A summary of the analysis.
  5. High-level content recommendations based on the analysis.
```

With this in mind. I'm ready to move on to the 'prepare' phase of my analysis.

## Stage 2: Prepare
The data used in this case study is Fitbit Fitness Tracker from Kaggle generated by a survey from Amazon Mechanical Turk between March 12th, 2016, and May 12th, 2016. It contains the personal fitness tracker information from 30 Fitbit users who consented to the use of their personal activity information including daily activity, steps, and heart rate. This data is stored in 18 .csv files.

### Data Integrity & Limitations
At the time of writing, it is June 2023. This data was collected in 2016 meaning it may not be relevant to the company anymore due to a change in a user's activity, sleep, and lifestyle in the last seven years. Additionally, the small sample size of 30 is inadequate to represent the entirety of the female Fitbit user population. Finally, the data contains no information on the age of each individual, a crucial metric when analyzing health and fitness.

A good data source is reliable, original, comprehensive, current, and cited (ROCCC). Using this to check the Fitbit user data:

- [ ] Reliable
  - Unreliable due to the small sample size.
- [ ] Original
  - Unoriginal data as it was collected by a third party.
- [X] Comprehensive
  - Collected data matches Bellabeat products.
- [ ] Current
  - Not current as data was collected over seven years ago.
- [ ] Cited
  - Not cited, third-party data.

Using this check, we can see the Fitbit data only meets one of our five criteria to be a good data source. I will continue with my analysis, however, there will be an asterisk so to speak on any conclusions drawn from this dataset as it is unfit for use in a professional setting.

## Stage 3: Process

As there is a relatively large number of .csv files and R or Python are better suited than spreadsheets for this analysis, and R programming has been used for this particular case study in RStudio Cloud.

This section is particularly long as it goes into every step of my preparation for analysis. For reader convenience, a table of contents for this section has been provided below:
#### Section Links
  - [Installing & Loading Common Packages & Libraries](#installing--loading-common-packages--libraries)
  - [Importing Data Into R](#importing-data-into-r)
  - [Exploring Key Tables](#exploring-key-tables)
  - [Data Cleaning](#data-cleaning)
    - [Checking Data Values](#checking-for-data-values)
    - [Checking for Missing Values](#checking-for-missing-values)
    - [Checking Number of Unique Participiants](#checking-number-of-unique-participants)
  - [Data Summary](#data-summary)

### Installing & Loading Common Packages & Libraries
'##' *Indicates a console output.*

```r
install.packages('tidyverse')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(tidyverse)

## ── Attaching core tidyverse packages ───────────────────────────── tidyverse 2.0.0 ──
## ✔ dplyr     1.1.2     ✔ readr     2.1.4
## ✔ forcats   1.0.0     ✔ stringr   1.5.0
## ✔ ggplot2   3.4.2     ✔ tibble    3.2.1
## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
## ✔ purrr     1.0.1 
## ── Conflicts ─────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
```
```r
install.packages('here')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(here)

## here() starts at /cloud/project
```
```r
install.packages('skimr')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(skimr)

## Attaching package: 'skimr'
```
```r
install.packages('janitor')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(janitor)

## Attaching package: ‘janitor’
##
## The following objects are masked from 'package:stats':
## 
##     chisq.test, fisher.test
```
```r
install.packages('dplyr')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(dplyr)

## Attaching package: ‘dplyr’
```
```r
install.packages('ggplot2')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(ggplot2)
```
```r
install.packages('lubridate')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
## (as ‘lib’ is unspecified)
```
```r
library(lubridate)

## Attaching package: ‘lubridate’
##
## The following objects are masked from ‘package:base’:
##
##     date, intersect, setdiff, union
```
```r
install.packages('RColorBrewer')

## Installing package into ‘/cloud/lib/x86_64-pc-linux-gnu-library/4.3’
##(as ‘lib’ is unspecified)
```
```r
library(RColorBrewer)
```

In order to make the findings of the analysis more accessible, I then selected a colorblind-friendly color pallet using RColorBrewer. I wanted a vibrant, high-contrast, limited color pallet in order to make sure that all viewers of the graphs and charts are easily able to distinguish between categories.

```r
display.brewer.all(colorblindFriendly = T)
```
![RColorBrewer Colorblind Pallets](https://github.com/powellot/GoogleCareerCertificate/blob/main/Resources/brewerColorBlind.png)

*All brewer color pallets that are colorblind-friendly.*

```r
display.brewer.pal(5, "Set2")
```
![RColorBrewer pallet I use](https://github.com/powellot/GoogleCareerCertificate/blob/main/Resources/brewerColorBlindPallet.png)

*The brewer color pallet I will be using for this analysis.*

### Importing Data Into R
To begin, I created two data frames 'day_activity' and 'sleep_day' from the CSV files from the datasets.
```r
daily_activity <- read.csv("dailyActivity_merged.csv")
sleep_day <- read.csv("sleepDay_merged.csv")
```
### Exploring Key Tables
This was to check the basic information of each dataset. Namely the column names, number of observations, data type, formatting, and be sure there were no missing values.

Taking a look at the 'daily_activity' data:
```r
head(daily_activity)

##           Id ActivityDate TotalSteps TotalDistance TrackerDistance LoggedActivitiesDistance VeryActiveDistance
## 1 1503960366    4/12/2016      13162          8.50            8.50                        0               1.88
## 2 1503960366    4/13/2016      10735          6.97            6.97                        0               1.57
## 3 1503960366    4/14/2016      10460          6.74            6.74                        0               2.44
## 4 1503960366    4/15/2016       9762          6.28            6.28                        0               2.14
## 5 1503960366    4/16/2016      12669          8.16            8.16                        0               2.71
## 6 1503960366    4/17/2016       9705          6.48            6.48                        0               3.19
##   ModeratelyActiveDistance LightActiveDistance SedentaryActiveDistance VeryActiveMinutes FairlyActiveMinutes
## 1                     0.55                6.06                       0                25                  13
## 2                     0.69                4.71                       0                21                  19
## 3                     0.40                3.91                       0                30                  11
## 4                     1.26                2.83                       0                29                  34
## 5                     0.41                5.04                       0                36                  10
## 6                     0.78                2.51                       0                38                  20
##   LightlyActiveMinutes SedentaryMinutes Calories
## 1                  328              728     1985
## 2                  217              776     1797
## 3                  181             1218     1776
## 4                  209              726     1745
## 5                  221              773     1863
## 6                  164              539     1728
```

Identifying all of the column names in the 'daily_activity' data:
```r
colnames(daily_activity)

##  [1] "Id"                       "ActivityDate"             "TotalSteps"               "TotalDistance"           
##  [5] "TrackerDistance"          "LoggedActivitiesDistance" "VeryActiveDistance"       "ModeratelyActiveDistance"
##  [9] "LightActiveDistance"      "SedentaryActiveDistance"  "VeryActiveMinutes"        "FairlyActiveMinutes"     
## [13] "LightlyActiveMinutes"     "SedentaryMinutes"         "Calories"
```

Taking a look at the 'sleep_day' data:
```r
head(sleep_day)

##           Id              SleepDay TotalSleepRecords TotalMinutesAsleep TotalTimeInBed
## 1 1503960366 4/12/2016 12:00:00 AM                 1                327            346
## 2 1503960366 4/13/2016 12:00:00 AM                 2                384            407
## 3 1503960366 4/15/2016 12:00:00 AM                 1                412            442
## 4 1503960366 4/16/2016 12:00:00 AM                 2                340            367
## 5 1503960366 4/17/2016 12:00:00 AM                 1                700            712
## 6 1503960366 4/19/2016 12:00:00 AM                 1                304            320
```

Identifying all of the column names in the 'sleep_day' data:
```r
colnames(sleep_day)

## [1] "Id"                 "SleepDay"           "TotalSleepRecords"  "TotalMinutesAsleep" "TotalTimeInBed"  
```

Using this information, I was able to see that the "Id" field is shared between the two datasets meaning I can use that information to merge the two datasets.
